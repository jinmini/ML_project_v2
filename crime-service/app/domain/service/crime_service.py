import numpy as np
from sklearn import preprocessing
import pandas as pd
import os
import folium
from app.domain.model.data_save import save_dir
from app.domain.model.crime_schema import Dataset
from app.domain.model.google_schema import GoogleMap
from app.domain.model.reader_schema import Datareader
import json
from fastapi import Response
from fastapi.responses import JSONResponse

class CrimeService:

    def __init__(self):
        self.data_reader = Datareader()
        self.dataset = Dataset()
        self.crime_rate_columns = ['ì‚´ì¸ê²€ê±°ìœ¨', 'ê°•ë„ê²€ê±°ìœ¨', 'ê°•ê°„ê²€ê±°ìœ¨', 'ì ˆë„ê²€ê±°ìœ¨', 'í­ë ¥ê²€ê±°ìœ¨']
        self.crime_columns = ['ì‚´ì¸', 'ê°•ë„', 'ê°•ê°„', 'ì ˆë„', 'í­ë ¥']

    def preprocess(self, *args) -> Dataset:
        """íŒŒì¼ ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜"""
        print(f"------------ëª¨ë¸ ì „ì²˜ë¦¬ ì‹œì‘-----------")

        for i in list(args):
            # print(f"args ê°’ ì¶œë ¥: {i}")
            self.save_object_to_csv(i)
        return self.dataset
    
    def create_matrix(self, fname) -> object:
        self.data_reader.fname = fname

        if fname.endswith('.csv'):
            return self.data_reader.csv_to_dframe()
        elif fname.endswith('.xls') or fname.endswith('.xlsx'):
            return self.data_reader.xls_to_dframe(header=2, usecols='B,D,G,J,N')
        else:
            raise ValueError(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {fname}")

    def save_object_to_csv(self, fname) -> None:
        print(f"ğŸŒ±save_csv ì‹¤í–‰ : {fname}")
        full_name = os.path.join(save_dir, fname)

        if not os.path.exists(full_name) and fname == "cctv_in_seoul.csv":
            self.dataset.cctv = self.create_matrix(fname)
            self.update_cctv()
            
        elif not os.path.exists(full_name) and fname == "crime_in_seoul.csv":
            self.dataset.crime = self.create_matrix(fname)
            self.update_crime() 
            self.update_police() 

        elif not os.path.exists(full_name) and fname == "pop_in_seoul.xls":
            self.dataset.pop = self.create_matrix(fname)
            self.update_pop()

        else:
            print(f"íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤. {fname}")

    def update_cctv(self) -> None:
        self.dataset.cctv = self.dataset.cctv.drop(['2013ë…„ë„ ì´ì „', '2014ë…„', '2015ë…„', '2016ë…„'], axis=1)
        print(f"CCTV ë°ì´í„° í—¤ë“œ: {self.dataset.cctv.head()}")
        cctv = self.dataset.cctv
        cctv = cctv.rename(columns={'ê¸°ê´€ëª…': 'ìì¹˜êµ¬'})
        self.dataset.cctv = cctv
  
    def update_crime(self) -> None:
        gmaps = GoogleMap()

        print(f"CRIME ë°ì´í„° í—¤ë“œ: {self.dataset.crime.head()}")
        crime = self.dataset.crime
        station_names = [] # ê²½ì°°ì„œ ê´€ì„œëª… ë¦¬ìŠ¤íŠ¸

        for name in crime['ê´€ì„œëª…']:
            station_names.append('ì„œìš¸' + str(name[:-1]) + 'ê²½ì°°ì„œ')
        print(f"ğŸ”¥ğŸ’§ê²½ì°°ì„œ ê´€ì„œëª… ë¦¬ìŠ¤íŠ¸: {station_names}")

        station_addrs = []
        station_lats = []
        station_lngs = []

        for name in station_names:
            tmp = gmaps.geocode(name, language='ko')
            print(f"""{name}ì˜ ê²€ìƒ‰ ê²°ê³¼: {tmp[0].get("formatted_address")}""")
            station_addrs.append(tmp[0].get("formatted_address"))
            tmp_loc = tmp[0].get("geometry")
            station_lats.append(tmp_loc['location']['lat'])
            station_lngs.append(tmp_loc['location']['lng'])
            
        print(f"ğŸ”¥ğŸ’§ìì¹˜êµ¬ ë¦¬ìŠ¤íŠ¸: {station_addrs}")
        gu_names = []
        for addr in station_addrs:
            tmp = addr.split()
            tmp_gu = [gu for gu in tmp if gu[-1] == 'êµ¬'][0]
            gu_names.append(tmp_gu)
    
        crime['ìì¹˜êµ¬'] = gu_names

        crime.to_csv(os.path.join(save_dir, 'crime_in_seoul.csv'), index=False)
        self.dataset.crime = crime
    
    def update_police(self) -> None:
        crime = self.dataset.crime

        police = pd.pivot_table(crime, index='ìì¹˜êµ¬', aggfunc=np.sum)

        # âœ… ê²€ê±°ìœ¨ ê³„ì‚°
        for crime_type in ['ì‚´ì¸', 'ê°•ë„', 'ê°•ê°„', 'ì ˆë„', 'í­ë ¥']:
            police[f'{crime_type}ê²€ê±°ìœ¨'] = (police[f'{crime_type} ê²€ê±°'] / police[f'{crime_type} ë°œìƒ']) * 100

        # âœ… ê²€ê±°ìœ¨ 100% ì´ˆê³¼ê°’ ì¡°ì •
        for col in self.crime_rate_columns:
            police[col] = police[col].apply(lambda x: min(x, 100))

        police.reset_index(inplace=True)  # âœ… `ìì¹˜êµ¬`ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë³€í™˜
        police = police[['ìì¹˜êµ¬', 'ì‚´ì¸ê²€ê±°ìœ¨', 'ê°•ë„ê²€ê±°ìœ¨', 'ê°•ê°„ê²€ê±°ìœ¨', 'ì ˆë„ê²€ê±°ìœ¨', 'í­ë ¥ê²€ê±°ìœ¨']]  # âœ… ì»¬ëŸ¼ ì •ë¦¬
        police = police.round(1)  # âœ… ì†Œìˆ˜ì  ì²«ì§¸ ìë¦¬ ë°˜ì˜¬ë¦¼

        police.to_csv(os.path.join(save_dir, 'police_in_seoul.csv'), index=False) 

        x = police[self.crime_rate_columns].values
        min_max_scalar = preprocessing.MinMaxScaler()
        """
          ìŠ¤ì¼€ì¼ë§ì€ ì„ í˜•ë³€í™˜ì„ ì ìš©í•˜ì—¬
          ì „ì²´ ìë£Œì˜ ë¶„í¬ë¥¼ í‰ê·  0, ë¶„ì‚° 1ì´ ë˜ë„ë¡ ë§Œë“œëŠ” ê³¼ì •
          """
        x_scaled = min_max_scalar.fit_transform(x.astype(float))
        """
         ì •ê·œí™” normalization
         ë§ì€ ì–‘ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•¨ì— ìˆì–´ ë°ì´í„°ì˜ ë²”ìœ„(ë„ë©”ì¸)ë¥¼ ì¼ì¹˜ì‹œí‚¤ê±°ë‚˜
         ë¶„í¬(ìŠ¤ì¼€ì¼)ë¥¼ ìœ ì‚¬í•˜ê²Œ ë§Œë“œëŠ” ì‘ì—…
         """
        police_norm = pd.DataFrame(x_scaled, columns=self.crime_columns, index=police.index)
        police_norm[self.crime_rate_columns] = police[self.crime_rate_columns]
        police_norm['ë²”ì£„'] = np.sum(police_norm[self.crime_rate_columns], axis=1)
        police_norm['ê²€ê±°'] = np.sum(police_norm[self.crime_columns], axis=1)
        police_norm.to_csv(os.path.join(save_dir, 'police_norm_in_seoul.csv'))

        self.dataset.police = police

    def update_pop(self) -> None:
        pop = self.dataset.pop
        pop = pop.rename(columns={
            # pop.columns[0] : 'ìì¹˜êµ¬',  # ë³€ê²½í•˜ì§€ ì•ŠìŒ
            pop.columns[1]: 'ì¸êµ¬ìˆ˜',   
            pop.columns[2]: 'í•œêµ­ì¸',
            pop.columns[3]: 'ì™¸êµ­ì¸',
            pop.columns[4]: 'ê³ ë ¹ì',})
        self.dataset.pop = pop

        pop.drop([26], inplace=True)
        pop['ì™¸êµ­ì¸ë¹„ìœ¨'] = pop['ì™¸êµ­ì¸'].astype(int) / pop['ì¸êµ¬ìˆ˜'].astype(int) * 100
        pop['ê³ ë ¹ìë¹„ìœ¨'] = pop['ê³ ë ¹ì'].astype(int) / pop['ì¸êµ¬ìˆ˜'].astype(int) * 100

        cctv_pop = pd.merge(self.dataset.cctv, pop, on='êµ¬ë³„')
        cor1 = np.corrcoef(cctv_pop['ê³ ë ¹ìë¹„ìœ¨'], cctv_pop['ì†Œê³„'])
        cor2 = np.corrcoef(cctv_pop['ì™¸êµ­ì¸ë¹„ìœ¨'], cctv_pop['ì†Œê³„'])
        print(f'ê³ ë ¹ìë¹„ìœ¨ê³¼ CCTVì˜ ìƒê´€ê³„ìˆ˜ {str(cor1)} \n'
              f'ì™¸êµ­ì¸ë¹„ìœ¨ê³¼ CCTVì˜ ìƒê´€ê³„ìˆ˜ {str(cor2)} ')

        print(f"ğŸ”¥ğŸ’§ì¸êµ¬ ë°ì´í„° í—¤ë“œ: {self.dataset.pop.head()}")

    def draw_crime_map(self) -> object:
        try:
            # ë°ì´í„° í´ë” ì„¤ì • ë° í™•ì¸
            data_dir = 'app/updated_data'  # í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
            output_dir = 'app/saved_data'  # ê²°ê³¼ë¬¼ ì €ì¥ ê²½ë¡œ
            
            # ì¶œë ¥ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(output_dir, exist_ok=True)
            print(f"ì¶œë ¥ ë””ë ‰í† ë¦¬ í™•ì¸: {output_dir}")
            
            # ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            os.makedirs(data_dir, exist_ok=True)
            print(f"ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸: {data_dir}")
            
            # íŒŒì¼ ì½ê¸°
            print("ë°ì´í„° ë¡œë“œ ì¤‘...")
            
            try:
                police_norm = pd.read_csv(f'{data_dir}/police_norm_in_seoul.csv')
                print(f"police_norm_in_seoul.csv íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            except FileNotFoundError:
                print(f"ê²½ê³ : {data_dir}/police_norm_in_seoul.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                # ê¸°ë³¸ police_norm ë°ì´í„° ìƒì„±
                police_norm = pd.DataFrame({
                    'ìì¹˜êµ¬': ['ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬'],
                    'ì‚´ì¸': [0.3, 0.5, 0.7],
                    'ê°•ë„': [0.2, 0.4, 0.6],
                    'ê°•ê°„': [0.5, 0.3, 0.2],
                    'ì ˆë„': [0.4, 0.6, 0.8],
                    'í­ë ¥': [0.7, 0.5, 0.3],
                    'ì‚´ì¸ê²€ê±°ìœ¨': [90, 85, 80],
                    'ê°•ë„ê²€ê±°ìœ¨': [85, 80, 75],
                    'ê°•ê°„ê²€ê±°ìœ¨': [80, 75, 70],
                    'ì ˆë„ê²€ê±°ìœ¨': [75, 70, 65],
                    'í­ë ¥ê²€ê±°ìœ¨': [70, 65, 60],
                    'ë²”ì£„': [0.5, 0.4, 0.6],
                    'ê²€ê±°': [0.8, 0.7, 0.6]
                })
                # íŒŒì¼ ì €ì¥
                police_norm.to_csv(f'{data_dir}/police_norm_in_seoul.csv', index=False)
                print(f"ê¸°ë³¸ police_norm ë°ì´í„°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            try:
                crime = pd.read_csv(f'{data_dir}/crime_in_seoul.csv')
                print(f"crime_in_seoul.csv íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            except FileNotFoundError:
                print(f"ê²½ê³ : {data_dir}/crime_in_seoul.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                # ê¸°ë³¸ crime ë°ì´í„° ìƒì„±
                crime = pd.DataFrame({
                    'ê´€ì„œëª…': ['ê°•ë‚¨ê²½ì°°ì„œ', 'ê°•ë™ê²½ì°°ì„œ', 'ê°•ë¶ê²½ì°°ì„œ'],
                    'ì‚´ì¸ ë°œìƒ': [2, 3, 4],
                    'ì‚´ì¸ ê²€ê±°': [2, 2, 3],
                    'ê°•ë„ ë°œìƒ': [5, 6, 7],
                    'ê°•ë„ ê²€ê±°': [4, 5, 6],
                    'ê°•ê°„ ë°œìƒ': [10, 11, 12],
                    'ê°•ê°„ ê²€ê±°': [8, 9, 10],
                    'ì ˆë„ ë°œìƒ': [100, 110, 120],
                    'ì ˆë„ ê²€ê±°': [80, 85, 90],
                    'í­ë ¥ ë°œìƒ': [150, 160, 170],
                    'í­ë ¥ ê²€ê±°': [130, 140, 150],
                    'ìì¹˜êµ¬': ['ê°•ë‚¨êµ¬', 'ê°•ë™êµ¬', 'ê°•ë¶êµ¬']
                })
                # íŒŒì¼ ì €ì¥
                crime.to_csv(f'{data_dir}/crime_in_seoul.csv', index=False)
                print(f"ê¸°ë³¸ crime ë°ì´í„°ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
            
            # police_norm ë°ì´í„° ì „ì²˜ë¦¬ (ì¸ë±ìŠ¤ê°€ ìì¹˜êµ¬ì¸ ê²½ìš°)
            if police_norm.columns[0] == '':
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ ë¹„ì–´ìˆëŠ” ê²½ìš° (ì¸ë±ìŠ¤ë¡œ í‘œì‹œë¨)
                police_norm = police_norm.iloc[:, 1:]  # ì²« ë²ˆì§¸ ë¹ˆ ì»¬ëŸ¼ ì œê±°
                
                # ìì¹˜êµ¬ ì •ë³´ ì¶”ê°€
                if not 'ìì¹˜êµ¬' in police_norm.columns and not 'êµ¬ë³„' in police_norm.columns:
                    # CCTV ë°ì´í„°ì—ì„œ ìì¹˜êµ¬ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    try:
                        cctv_data = pd.read_csv(f'{data_dir}/cctv_in_seoul.csv')
                        if 'ìì¹˜êµ¬' in cctv_data.columns:
                            police_norm['ìì¹˜êµ¬'] = cctv_data['ìì¹˜êµ¬'].values[:len(police_norm)]
                        else:
                            police_norm['ìì¹˜êµ¬'] = cctv_data.iloc[:, 0].values[:len(police_norm)]
                    except Exception as e:
                        print(f"ìì¹˜êµ¬ ì •ë³´ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                        # ì„ì‹œ ìì¹˜êµ¬ ì´ë¦„ ìƒì„±
                        police_norm['ìì¹˜êµ¬'] = [f"êµ¬_{i}" for i in range(len(police_norm))]
            
            # ìì¹˜êµ¬ ì»¬ëŸ¼ëª… í†µì¼
            if 'êµ¬ë³„' in police_norm.columns and not 'ìì¹˜êµ¬' in police_norm.columns:
                police_norm['ìì¹˜êµ¬'] = police_norm['êµ¬ë³„']
            
            # geo_simple.json íŒŒì¼ ë¡œë“œ
            try:
                with open(f'{data_dir}/geo_simple.json', 'r', encoding='utf-8') as f:
                    state_geo = json.load(f)
                print(f"geo_simple.json íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            except FileNotFoundError:
                print(f"ê²½ê³ : {data_dir}/geo_simple.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("ì„œìš¸ì‹œ êµ¬ë³„ ì§€ë¦¬ ì •ë³´ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                
                # ê°„ë‹¨í•œ ì„œìš¸ì‹œ êµ¬ë³„ GeoJSON ìƒì„± (ìµœì†Œí•œì˜ ì •ë³´ë§Œ í¬í•¨)
                state_geo = {
                    "type": "FeatureCollection",
                    "features": [
                        {
                            "type": "Feature",
                            "id": "ê°•ë‚¨êµ¬",
                            "properties": {"name": "ê°•ë‚¨êµ¬"},
                            "geometry": {
                                "type": "Polygon",
                                "coordinates": [[[127.0495, 37.5173], [127.0657, 37.5173], [127.0657, 37.5275], [127.0495, 37.5275], [127.0495, 37.5173]]]
                            }
                        },
                        {
                            "type": "Feature",
                            "id": "ê°•ë™êµ¬",
                            "properties": {"name": "ê°•ë™êµ¬"},
                            "geometry": {
                                "type": "Polygon",
                                "coordinates": [[[127.1421, 37.5282], [127.1583, 37.5282], [127.1583, 37.5384], [127.1421, 37.5384], [127.1421, 37.5282]]]
                            }
                        },
                        {
                            "type": "Feature",
                            "id": "ê°•ë¶êµ¬",
                            "properties": {"name": "ê°•ë¶êµ¬"},
                            "geometry": {
                                "type": "Polygon",
                                "coordinates": [[[127.0110, 37.6282], [127.0272, 37.6282], [127.0272, 37.6384], [127.0110, 37.6384], [127.0110, 37.6282]]]
                            }
                        }
                    ]
                }
                
                # íŒŒì¼ ì €ì¥ (í–¥í›„ ì‚¬ìš©ì„ ìœ„í•´)
                try:
                    with open(f'{data_dir}/geo_simple.json', 'w', encoding='utf-8') as f:
                        json.dump(state_geo, f, ensure_ascii=False)
                    print(f"ê¸°ë³¸ ì§€ë¦¬ ì •ë³´ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {data_dir}/geo_simple.json")
                except Exception as e:
                    print(f"ì§€ë¦¬ ì •ë³´ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {str(e)}")

            # ê²½ì°°ì„œ ìœ„ì¹˜ ì •ë³´ ë¡œë“œ ì‹œë„
            try:
                police_pos = pd.read_csv(f'{data_dir}/police_pos.csv')
                print(f"police_pos.csv íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
            except FileNotFoundError:
                print(f"ê²½ê³ : {data_dir}/police_pos.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                print("ê¸°ë³¸ ê²½ì°°ì„œ ìœ„ì¹˜ ì •ë³´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                
                # ê¸°ë³¸ police_pos ë°ì´í„° ìƒì„±
                police_pos = pd.DataFrame({
                    'ê´€ì„œëª…': ['ê°•ë‚¨ê²½ì°°ì„œ', 'ê°•ë™ê²½ì°°ì„œ', 'ê°•ë¶ê²½ì°°ì„œ'],
                    'lat': [37.5172, 37.5382, 37.6382],
                    'lng': [127.0473, 127.1382, 127.0282],
                    'ì‚´ì¸ ê²€ê±°': [2, 2, 3],
                    'ê°•ë„ ê²€ê±°': [4, 5, 6],
                    'ê°•ê°„ ê²€ê±°': [8, 9, 10],
                    'ì ˆë„ ê²€ê±°': [80, 85, 90],
                    'í­ë ¥ ê²€ê±°': [130, 140, 150]
                })
                
                # ê²€ê±°ìœ¨ ê³„ì‚°
                col = ['ì‚´ì¸ ê²€ê±°', 'ê°•ë„ ê²€ê±°', 'ê°•ê°„ ê²€ê±°', 'ì ˆë„ ê²€ê±°', 'í­ë ¥ ê²€ê±°']
                tmp = police_pos[col] / police_pos[col].max()
                police_pos['ê²€ê±°'] = np.sum(tmp, axis=1)
                
                # íŒŒì¼ ì €ì¥
                police_pos.to_csv(f'{data_dir}/police_pos.csv', index=False)
                print(f"ê¸°ë³¸ ê²½ì°°ì„œ ìœ„ì¹˜ ì •ë³´ íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {data_dir}/police_pos.csv")

            print("ì§€ë„ ìƒì„± ì¤‘...")
            print(f"police_norm ë°ì´í„° ì»¬ëŸ¼: {police_norm.columns.tolist()}")
            
            # ê¸°ë³¸ ì§€ë„ ìƒì„±
            folium_map = folium.Map(location=[37.5502, 126.982], zoom_start=12, tiles='OpenStreetMap')
            
            # ë²”ì£„ìœ¨ Choropleth ì¶”ê°€
            try:
                # ìì¹˜êµ¬ ì»¬ëŸ¼ê³¼ ë²”ì£„ ì»¬ëŸ¼ í™•ì¸
                district_col = None
                for col_name in ['ìì¹˜êµ¬', 'êµ¬ë³„']:
                    if col_name in police_norm.columns:
                        district_col = col_name
                        break
                
                crime_col = None
                for col_name in ['ë²”ì£„', 'ë²”ì£„ìœ¨']:
                    if col_name in police_norm.columns:
                        crime_col = col_name
                        break
                
                if district_col is not None and crime_col is not None:
                    folium.Choropleth(
                        geo_data=state_geo,
                        data=tuple(zip(police_norm[district_col], police_norm[crime_col])),
                        columns=["State", "Crime Rate"],
                        key_on="feature.id",
                        fill_color="PuRd",
                        fill_opacity=0.7,
                        line_opacity=0.2,
                        legend_name="ë²”ì£„ ë°œìƒë¥  (%)",
                        reset=True,
                    ).add_to(folium_map)
                    print(f"êµ¬ë³„ ë²”ì£„ìœ¨ ì‹œê°í™” ì™„ë£Œ (ì»¬ëŸ¼: {district_col}, {crime_col})")
                else:
                    print(f"ê²½ê³ : police_norm ë°ì´í„°ì— ì ì ˆí•œ êµ¬ë³„ ì»¬ëŸ¼({district_col})ì´ë‚˜ ë²”ì£„ ì»¬ëŸ¼({crime_col})ì´ ì—†ìŠµë‹ˆë‹¤.")
                    print(f"ê°€ìš©í•œ ì»¬ëŸ¼: {police_norm.columns.tolist()}")
            except Exception as e:
                print(f"Choropleth ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                import traceback
                print(traceback.format_exc())
            
            # ê²½ì°°ì„œ ìœ„ì¹˜ ë§ˆì»¤ ì¶”ê°€ (ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°)
            if police_pos is not None and 'lat' in police_pos.columns and 'lng' in police_pos.columns:
                try:
                    # ê²€ê±°ìœ¨ ì»¬ëŸ¼ í™•ì¸
                    if 'ê²€ê±°' not in police_pos.columns:
                        # ê²€ê±°ìœ¨ ê³„ì‚° (availableí•œ ì»¬ëŸ¼ í™•ì¸)
                        detection_cols = [col for col in police_pos.columns if 'ê²€ê±°' in col]
                        if detection_cols:
                            print(f"ê²€ê±°ìœ¨ ê³„ì‚°ì— ì‚¬ìš©í•  ì»¬ëŸ¼: {detection_cols}")
                            tmp = police_pos[detection_cols] / police_pos[detection_cols].max()
                            police_pos['ê²€ê±°'] = np.sum(tmp, axis=1)
                        else:
                            police_pos['ê²€ê±°'] = 1  # ê¸°ë³¸ê°’
                    
                    # ë§ˆì»¤ ì¶”ê°€
                    for i in police_pos.index:
                        folium.CircleMarker(
                            [police_pos['lat'][i], police_pos['lng'][i]],
                            radius=police_pos['ê²€ê±°'][i] * 10 if 'ê²€ê±°' in police_pos.columns else 5,
                            fill_color='#0a0a32',
                            popup=f"ê²€ê±°ìœ¨: {police_pos['ê²€ê±°'][i]:.2f}" if 'ê²€ê±°' in police_pos.columns else "ê²½ì°°ì„œ"
                        ).add_to(folium_map)
                    
                    print("ê²½ì°°ì„œ ìœ„ì¹˜ ë§ˆì»¤ ì¶”ê°€ ì™„ë£Œ")
                except Exception as e:
                    print(f"ë§ˆì»¤ ì¶”ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            
            # ì§€ë„ ì €ì¥
            output_path = f'{output_dir}/crime_map.html'
            folium_map.save(output_path)
            print(f"ì§€ë„ê°€ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
            
            return {"status": "success", "file_path": output_path}
            
        except Exception as e:
            print(f"ì§€ë„ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            import traceback
            print(traceback.format_exc())
            return {"status": "error", "message": str(e)}

    # @staticmethod
    # def merge_datasets():
    #     saved_dir = r"C:\\Users\\bitcamp\\Documents\\2025\\25ep_python(esg)\\Crimecity_250220\\com\saved_datas"

    #     cctv_file = os.path.join(saved_dir, "cctv_in_seoul_processed.csv")
    #     crime_file = os.path.join(saved_dir, "police_position.csv")
    #     pop_file = os.path.join(saved_dir, "pop_in_seoul_preprocess.csv")

    #     cctv_df = pd.read_csv(cctv_file, encoding='utf-8-sig')
    #     crime_df = pd.read_csv(crime_file, encoding='utf-8-sig')
    #     pop_df = pd.read_csv(pop_file, encoding='utf-8-sig')

    #     print("âœ… CCTV ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", cctv_df.shape)
    #     print("âœ… ë²”ì£„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", crime_df.shape)
    #     print("âœ… ì¸êµ¬ ë°ì´í„° ë¡œë“œ ì™„ë£Œ:", pop_df.shape)

    #     merged_df = pd.merge(cctv_df, crime_df, on="ìì¹˜êµ¬", how="inner")
    #     merged_df = pd.merge(merged_df, pop_df, on="ìì¹˜êµ¬", how="inner")

    #     print("âœ… ìµœì¢… ë°ì´í„° ë³‘í•© ì™„ë£Œ:", merged_df.shape)
    #     print("âœ… ìµœì¢… ë°ì´í„° ìƒìœ„ 5ê°œ í–‰:\n", merged_df.head())

    #     final_save_path = os.path.join(saved_dir, "seoul_final_dataset.csv")
    #     merged_df.to_csv(final_save_path, index=False, encoding='utf-8-sig')
    #     print(f"âœ… ìµœì¢… ë°ì´í„° ì €ì¥ ì™„ë£Œ: {final_save_path}")

    #     pass